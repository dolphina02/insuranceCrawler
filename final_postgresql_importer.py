#!/usr/bin/env python3
"""
ìµœì¢… PostgreSQL ì„í¬í„° - ì „ì²´ ë°ì´í„° (ê¸°ì¤€ì¼ì í¬í•¨)
"""

import pandas as pd
import psycopg2
from datetime import datetime
import logging
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def final_import_to_postgresql():
    connection_string = "postgresql://neondb_owner:npg_xnKiwN18QFSu@ep-square-shadow-a174zj2p-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require"
    
    # ìµœì‹  CSV íŒŒì¼ ì°¾ê¸°
    csv_files = []
    for file in os.listdir('downloads'):
        if file.startswith('insurance_products_full_') and file.endswith('.csv'):
            csv_files.append(os.path.join('downloads', file))
    
    if not csv_files:
        print("âŒ downloads í´ë”ì—ì„œ insurance_products_full_*.csv íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    latest_csv = max(csv_files, key=os.path.getmtime)
    logger.info(f"ì‚¬ìš©í•  CSV íŒŒì¼: {latest_csv}")
    
    try:
        # PostgreSQL ì—°ê²°
        conn = psycopg2.connect(connection_string)
        cursor = conn.cursor()
        logger.info("PostgreSQL ì—°ê²° ì™„ë£Œ")
        
        # CSV íŒŒì¼ ì½ê¸°
        df = pd.read_csv(latest_csv)
        logger.info(f"CSV íŒŒì¼ ë¡œë“œ: {df.shape}")
        
        # ê¸°ì¤€ì¼ì ìƒì„±
        data_date = datetime.now().strftime('%Y%m%d')
        
        # ìµœì¢… í…Œì´ë¸” ì‚­ì œ ë° ìƒì„±
        cursor.execute("DROP TABLE IF EXISTS insurance_products_final")
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (í…ŒìŠ¤íŠ¸ì—ì„œ ê²€ì¦ëœ ë°©ì‹)
        clean_columns = []
        for i, col in enumerate(df.columns):
            clean_col = f"col_{i:02d}_{col[:20].replace(' ', '_').replace('/', '_').replace('(', '').replace(')', '').lower()}"
            clean_col = ''.join(c for c in clean_col if c.isalnum() or c == '_')
            clean_columns.append(clean_col)
        
        # í…Œì´ë¸” ìƒì„±
        column_definitions = [
            "id SERIAL PRIMARY KEY", 
            f"data_date VARCHAR(8) NOT NULL DEFAULT '{data_date}'"
        ]
        column_definitions.extend([f"{clean_col} TEXT" for clean_col in clean_columns])
        column_definitions.append("created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
        
        create_sql = f"""
            CREATE TABLE insurance_products_final (
                {', '.join(column_definitions)}
            )
        """
        
        cursor.execute(create_sql)
        logger.info(f"ìµœì¢… í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {len(df.columns) + 3}ê°œ ì»¬ëŸ¼")
        
        # ë°ì´í„° ì‚½ì… ì¤€ë¹„
        insert_columns = ['data_date'] + clean_columns
        placeholders = ', '.join(['%s'] * len(insert_columns))
        
        insert_sql = f"""
            INSERT INTO insurance_products_final ({', '.join(insert_columns)})
            VALUES ({placeholders})
        """
        
        # ë°°ì¹˜ ì‚½ì…
        batch_size = 100
        inserted_count = 0
        batch_data = []
        
        for index, row in df.iterrows():
            try:
                values = [data_date]  # ê¸°ì¤€ì¼ì
                
                for col in df.columns:
                    value = row[col]
                    if pd.isna(value):
                        values.append(None)
                    else:
                        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
                        text_value = str(value).strip()
                        if len(text_value) > 5000:  # 5000ì ì œí•œ
                            text_value = text_value[:5000] + "..."
                        values.append(text_value)
                
                batch_data.append(values)
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì‚½ì…
                if len(batch_data) >= batch_size:
                    cursor.executemany(insert_sql, batch_data)
                    inserted_count += len(batch_data)
                    batch_data = []
                    
                    if inserted_count % 500 == 0:
                        logger.info(f"ì§„í–‰ë¥ : {inserted_count}/{len(df)}")
                        conn.commit()
                
            except Exception as e:
                logger.error(f"í–‰ {index} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch_data:
            cursor.executemany(insert_sql, batch_data)
            inserted_count += len(batch_data)
        
        conn.commit()
        
        # ê²°ê³¼ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM insurance_products_final")
        total_count = cursor.fetchone()[0]
        
        # ê¸°ì¤€ì¼ìë³„ í†µê³„
        cursor.execute("SELECT data_date, COUNT(*) FROM insurance_products_final GROUP BY data_date")
        date_stats = cursor.fetchall()
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        cursor.execute("SELECT col_00_category, COUNT(*) FROM insurance_products_final WHERE col_00_category IS NOT NULL GROUP BY col_00_category ORDER BY COUNT(*) DESC")
        category_stats = cursor.fetchall()
        
        # ë³´í—˜íšŒì‚¬ë³„ í†µê³„ (ìƒìœ„ 10ê°œ)
        cursor.execute("SELECT col_01_company_name, COUNT(*) FROM insurance_products_final WHERE col_01_company_name IS NOT NULL GROUP BY col_01_company_name ORDER BY COUNT(*) DESC LIMIT 10")
        company_stats = cursor.fetchall()
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ ìµœì¢… PostgreSQL ì„í¬íŠ¸ ì™„ë£Œ!")
        print(f"{'='*80}")
        print(f"í…Œì´ë¸”ëª…: insurance_products_final")
        print(f"ì´ ë ˆì½”ë“œ ìˆ˜: {total_count:,}ê°œ")
        print(f"ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns) + 3}ê°œ (data_date, id, created_at í¬í•¨)")
        print(f"ê¸°ì¤€ì¼ì: {data_date}")
        
        print(f"\nğŸ“… ê¸°ì¤€ì¼ìë³„ í†µê³„:")
        for date, cnt in date_stats:
            print(f"  {date}: {cnt:,}ê°œ")
        
        print(f"\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:")
        for category, cnt in category_stats:
            print(f"  {category}: {cnt:,}ê°œ")
        
        print(f"\nğŸ¢ ìƒìœ„ ë³´í—˜íšŒì‚¬:")
        for company, cnt in company_stats:
            print(f"  {company}: {cnt:,}ê°œ")
        
        print(f"\nğŸ” ë°ì´í„° í™•ì¸:")
        print("psql 'postgresql://neondb_owner:npg_xnKiwN18QFSu@ep-square-shadow-a174zj2p-pooler.ap-southeast-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require'")
        print("SELECT data_date, col_00_category, col_01_company_name, COUNT(*) FROM insurance_products_final GROUP BY data_date, col_00_category, col_01_company_name LIMIT 10;")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"ìµœì¢… ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ ìµœì¢… PostgreSQL ì„í¬íŠ¸ ì‹œì‘...")
    success = final_import_to_postgresql()
    
    if success:
        print("\nâœ… ìµœì¢… ì„í¬íŠ¸ ì„±ê³µ!")
        print("ëª¨ë“  ë³´í—˜ ë°ì´í„°ê°€ ê¸°ì¤€ì¼ìì™€ í•¨ê»˜ PostgreSQLì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("Daily ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        print("\nâŒ ìµœì¢… ì„í¬íŠ¸ ì‹¤íŒ¨!")